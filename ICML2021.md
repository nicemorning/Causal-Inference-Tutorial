*[Integer Programming for Causal Structure Learning in the Presence of Latent Variables](https://proceedings.mlr.press/v139/chen21c.html)

**ADMG(ancestral acyclic directed mixed graphs) Latent Variables  Despite their wide application, it is known that DAG models are not closed under marginalization. This implies that DAGs cannot be used to model structures involving latent variables which are the most common cases in practice.**

The problem of finding an ancestral acyclic directed mixed graph (ADMG) that represents the causal relationships between a set of variables is an important area of research on causal inference. Most existing score-based structure learning methods focus on learning directed acyclic graph (DAG) models without latent variables. A number of score-based methods have recently been proposed for the ADMG learning, yet they are heuristic in nature and do not guarantee an optimal solution. We propose a novel exact score-based method that solves an integer programming (IP) formulation and returns a score-maximizing ancestral ADMG for a set of continuous variables that follow a multivariate Gaussian distribution. We generalize the state-of-the-art IP model for DAG learning problems and derive new classes of valid inequalities to formulate an IP model for ADMG learning. Empirically, our model can be solved efficiently for medium-sized problems and achieves better accuracy than state-of-the-art score-based methods as well as benchmark constraint-based methods.

** [Estimating Identifiable Causal Effects on Markov Equivalence Class through Double Machine Learning](https://proceedings.mlr.press/v139/jung21b.html)

**partial ancestral graph (PAG) Most of this literature assumes that the underlying causal graph is completely specified. However, only observational data is
available in most practical settings, which means that one can learn at most a Markov equivalence class (MEC) of the underlying causal graph. In this paper, we study the problem of causal estimation from a MEC represented by a partial ancestral graph (PAG), which is learnable from observational data.**

General methods have been developed for estimating causal effects from observational data under causal assumptions encoded in the form of a causal graph. Most of this literature assumes that the underlying causal graph is completely specified. However, only observational data is available in most practical settings, which means that one can learn at most a Markov equivalence class (MEC) of the underlying causal graph. In this paper, we study the problem of causal estimation from a MEC represented by a partial ancestral graph (PAG), which is learnable from observational data. We develop a general estimator for any identifiable causal effects in a PAG. The result fills a gap for an end-to-end solution to causal inference from observational data to effects estimation. Specifically, we develop a complete identification algorithm that derives an influence function for any identifiable causal effects from PAGs. We then construct a double/debiased machine learning (DML) estimator that is robust to model misspecification and biases in nuisance function estimation, permitting the use of modern machine learning techniques. Simulation results corroborate with the theory.

** [Generative Causal Explanations for Graph Neural Networks](https://proceedings.mlr.press/v139/lin21d.html)

**To the best of our knowledge, while the notion of causality has been used for interpretable machine learning on images or texts, this is the first effort from a causal perspective to explain graph neural networks**

This paper presents Gem, a model-agnostic approach for providing interpretable explanations for any GNNs on various graph learning tasks. Specifically, we formulate the problem of providing explanations for the decisions of GNNs as a causal learning task. Then we train a causal explanation model equipped with a loss function based on Granger causality. Different from existing explainers for GNNs, Gem explains GNNs on graph-structured data from a causal perspective. It has better generalization ability as it has no requirements on the internal structure of the GNNs or prior knowledge on the graph learning tasks. In addition, Gem, once trained, can be used to explain the target GNN very quickly. Our theoretical analysis shows that several recent explainers fall into a unified framework of additive feature attribution methods. Experimental results on synthetic and real-world datasets show tha Gem achieves a relative increase of the explanation accuracy by up to 30 and speeds up the explanation process by up to 110Ã— as compared to its state-of-the-art alternatives.

[ICML2021 Causal Papers full list](https://github.com/nicemorning/Causal-Inference/edit/main/ICML2021.md)

[Recommended Readings](https://github.com/nicemorning/Causal-Inference/blob/main/papers_0320.md)



